{
  
    
        "post0": {
            "title": "6장 탐색",
            "content": "!pip install pandas==0.23.4 !pip install sklearn==0.21.0 !pip install yellowbrick==0.9 . Requirement already satisfied: pandas==0.23.4 in /usr/local/lib/python3.7/dist-packages (0.23.4) Requirement already satisfied: numpy&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4) (1.19.5) Requirement already satisfied: python-dateutil&gt;=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4) (2.8.1) Requirement already satisfied: pytz&gt;=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.23.4) (2018.9) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.5.0-&gt;pandas==0.23.4) (1.15.0) ERROR: Could not find a version that satisfies the requirement sklearn==0.21.0 (from versions: 0.0) ERROR: No matching distribution found for sklearn==0.21.0 Requirement already satisfied: yellowbrick==0.9 in /usr/local/lib/python3.7/dist-packages (0.9) Requirement already satisfied: scipy&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from yellowbrick==0.9) (1.4.1) Requirement already satisfied: cycler&gt;=0.10.0 in /usr/local/lib/python3.7/dist-packages (from yellowbrick==0.9) (0.10.0) Requirement already satisfied: numpy&gt;=1.13.0 in /usr/local/lib/python3.7/dist-packages (from yellowbrick==0.9) (1.19.5) Requirement already satisfied: matplotlib&lt;3.0,&gt;=1.5.1 in /usr/local/lib/python3.7/dist-packages (from yellowbrick==0.9) (2.2.5) Requirement already satisfied: scikit-learn&gt;=0.20 in /usr/local/lib/python3.7/dist-packages (from yellowbrick==0.9) (0.22.2.post1) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler&gt;=0.10.0-&gt;yellowbrick==0.9) (1.15.0) Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib&lt;3.0,&gt;=1.5.1-&gt;yellowbrick==0.9) (2018.9) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&lt;3.0,&gt;=1.5.1-&gt;yellowbrick==0.9) (2.4.7) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&lt;3.0,&gt;=1.5.1-&gt;yellowbrick==0.9) (1.3.1) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&lt;3.0,&gt;=1.5.1-&gt;yellowbrick==0.9) (2.8.1) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.20-&gt;yellowbrick==0.9) (1.0.1) . 6.1 &#45936;&#51060;&#53552;&#51032; &#53356;&#44592; . X.shape . (1309, 8) . &#50836;&#50557; &#53685;&#44228; . X.describe().iloc[:, [0, -1]] . pclass embarked_S . count 1309.000000 | 1309.000000 | . mean -0.012831 | 0.698243 | . std 0.995822 | 0.459196 | . min -1.551881 | 0.000000 | . 25% -0.363317 | 0.000000 | . 50% 0.825248 | 1.000000 | . 75% 0.825248 | 1.000000 | . max 0.825248 | 1.000000 | . &#55176;&#49828;&#53664;&#44536;&#47016; . fig, ax = plt.subplots(figsize=(6, 4)) X.fare.plot(kind=&quot;hist&quot;, ax=ax) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd70c5eae10&gt; . import seaborn as sns fig, ax = plt.subplots(figsize=(12, 8)) mask = y_train == 1 ax = sns.distplot(X_train[mask].fare, label=&#39;survived&#39;) ax = sns.distplot(X_train[~mask].fare, label=&#39;died&#39;) ax.set_xlim(-1.5, 1.5) ax.legend() . &lt;matplotlib.legend.Legend at 0x7fd70c5eaa10&gt; . 6.4 &#49328;&#51216;&#46020; . fig, ax = plt.subplots(figsize=(6, 4)) X.plot.scatter(x=&quot;age&quot;, y=&quot;fare&quot;, ax=ax, alpha=0.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6face1d10&gt; . X.age.corr(X.fare) . 0.1771997483998958 . 6.5 &#51312;&#51064;&#53944; &#54540;&#47215; . from yellowbrick.features import ( JointPlotVisualizer, ) fig, ax = plt.subplots(figsize=(6, 6)) jpv = JointPlotVisualizer(feature=&quot;age&quot;, target=&quot;fare&quot;) jpv.fit(X[&quot;age&quot;], X[&quot;fare&quot;]) jpv.poof() . from seaborn import jointplot fig, ax = plt.subplots(figsize=(6, 6)) new_df = X.copy() new_df[&quot;target&quot;] = y p = jointplot(&quot;age&quot;, &quot;fare&quot;, data=new_df, kind=&quot;reg&quot;) . 6.6 &#49933; &#44201;&#51088; . from seaborn import pairplot fig, ax = plt.subplots(figsize=(6, 6)) new_df = X.copy() new_df[&quot;target&quot;] = y vars = [&quot;pclass&quot;, &quot;age&quot;, &quot;fare&quot;] p = pairplot(new_df, vars=vars, hue=&quot;target&quot;, kind=&quot;reg&quot;) . 6.7 &#48149;&#49828; &#54540;&#47215;&#44284; &#48148;&#51060;&#50732;&#47536; &#54540;&#47215; . from seaborn import boxplot fig, ax = plt.subplots(figsize=(8, 6)) new_df = X.copy() new_df[&quot;target&quot;] = y boxplot(x=&quot;target&quot;, y=&quot;age&quot;, data=new_df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6fbbe6810&gt; . from seaborn import violinplot fig, ax = plt.subplots(figsize=(8, 6)) new_df = X.copy() new_df[&quot;target&quot;] = y violinplot(x=&quot;target&quot;, y=&quot;sex_male&quot;, data=new_df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6fbb7d910&gt; . 6.8 &#46160; &#49692;&#49436;&#54805; &#44050;&#51032; &#48708;&#44368; . fig, ax = plt.subplots(figsize=(8, 6)) ( X.assign( age_bin=pd.qcut(X.age, q=10, labels=False), class_bin=pd.cut(X.pclass, bins=3, labels=False), ) .groupby([&quot;age_bin&quot;, &quot;class_bin&quot;]) .size() .unstack() .pipe(lambda df: df.div(df.sum(1), axis=0)) .plot.bar(stacked=True, width=1, ax=ax, cmap=&quot;viridis&quot;) .legend(bbox_to_anchor=(1, 1)) ) . &lt;matplotlib.legend.Legend at 0x7fd6faa4c610&gt; . 6.9 &#49345;&#44288;&#44288;&#44228; . from yellowbrick.features import Rank2D fig, ax = plt.subplots(figsize=(6, 6)) pcv = Rank2D(features=X.columns, algorithm=&quot;pearson&quot;) pcv.fit(X, y) pcv.transform(X) pcv.poof() . from seaborn import heatmap fig, ax = plt.subplots(figsize=(8, 8)) ax = heatmap( X.corr(), fmt=&quot;.2f&quot;, annot=True, ax=ax, cmap=&quot;RdBu_r&quot;, vmin=-1, vmax=1, ) . X.corr().iloc[:, :2] . pclass age . pclass 1.000000 | -0.439704 | . age -0.439704 | 1.000000 | . sibsp 0.060832 | -0.292056 | . parch 0.018322 | -0.176447 | . fare -0.558827 | 0.177200 | . sex_male 0.124617 | 0.065004 | . embarked_Q 0.230491 | -0.053904 | . embarked_S 0.096335 | -0.045361 | . import numpy as np def correlated_columns(df, threshold=0.95): return ( df.corr().pipe( lambda df1: pd.DataFrame( np.tril(df1, k=-1), columns=df.columns, index=df.columns ) ) .stack() .rename(&quot;pearson&quot;) .pipe( lambda s: s[ s.abs() &gt; threshold ].reset_index() ) .query(&quot;level_0 not in level_1&quot;) ) correlated_columns(X) . level_0 level_1 pearson . 6.10 &#46972;&#46300;&#48708;&#51592; . from yellowbrick.features import RadViz fig, ax = plt.subplots(figsize=(6, 6)) rv = RadViz( classes=[&quot;died&quot;, &quot;survived&quot;], features=X.columns, ) rv.fit(X, y) _ = rv.transform(X) rv.poof() . from pandas.plotting import radviz fig, ax = plt.subplots(figsize=(6, 6)) new_df = X.copy() new_df[&quot;target&quot;] = y radviz(new_df, &quot;target&quot;, ax=ax, colormap=&quot;PiYG&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6fa9b63d0&gt; . 6.11 &#54217;&#54665; &#51340;&#54364; . from yellowbrick.features import ( ParallelCoordinates, ) fig, ax = plt.subplots(figsize=(6, 4)) pc = ParallelCoordinates( classes=[&quot;died&quot;, &quot;survived&quot;], features=X.columns, ) pc.fit(X, y) pc.transform(X) ax.set_xticklabels( ax.get_xticklabels(), rotation=45 ) pc.poof() . from pandas.plotting import ( parallel_coordinates, ) fig, ax = plt.subplots(figsize=(6, 4)) new_df = X.copy() new_df[&quot;target&quot;] = y parallel_coordinates( new_df, &quot;target&quot;, ax=ax, colormap=&quot;viridis&quot;, alpha=0.5, ) ax.set_xticklabels( ax.get_xticklabels(), rotation=45 ) . [Text(0,0,&#39;pclass&#39;), Text(0,0,&#39;age&#39;), Text(0,0,&#39;sibsp&#39;), Text(0,0,&#39;parch&#39;), Text(0,0,&#39;fare&#39;), Text(0,0,&#39;sex_male&#39;), Text(0,0,&#39;embarked_Q&#39;), Text(0,0,&#39;embarked_S&#39;)] .",
            "url": "https://deep-diver.github.io/pocket-ml-reference-korean/chapter6/",
            "relUrl": "/chapter6/",
            "date": " • Mar 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "5장 데이터의 정리",
            "content": "&#54596;&#50836;&#54620; &#54056;&#53412;&#51648; . 5.1 &#50676;&#51032; &#51060;&#47492; . import janitor as jn Xbad = pd.DataFrame( { &quot;A&quot;: [1, None, 3], &quot; sales numbers &quot;: [20.0, 30.0, None], } ) jn.clean_names(Xbad) . a _sales_numbers_ . 0 1.0 | 20.0 | . 1 NaN | 30.0 | . 2 3.0 | NaN | . def clean_col(name): return ( name.strip().lower().replace(&quot; &quot;, &quot;_&quot;) ) Xbad.rename(columns=clean_col) . a sales_numbers . 0 1.0 | 20.0 | . 1 NaN | 30.0 | . 2 3.0 | NaN | . 5.2 &#45572;&#46973;&#46108; &#44050;&#51032; &#44368;&#52404; . jn.coalesce( Xbad, columns=[&quot;A&quot;, &quot; sales numbers &quot;], new_column_name=&quot;val&quot;, ) . val . 0 1.0 | . 1 30.0 | . 2 3.0 | . Xbad.fillna(10) . A sales numbers . 0 1.0 | 20.0 | . 1 10.0 | 30.0 | . 2 3.0 | 10.0 | . jn.fill_empty( Xbad, columns=[&quot;A&quot;, &quot; sales numbers &quot;], value=10, ) . A sales numbers . 0 1.0 | 20.0 | . 1 10.0 | 30.0 | . 2 3.0 | 10.0 | . import pandas as pd url = &quot;https://biostat.app.vumc.org/wiki/pub/Main/DataSets/titanic3.xls&quot; df = pd.read_excel(url) orig_df = df df.isna().any().any() . True .",
            "url": "https://deep-diver.github.io/pocket-ml-reference-korean/chapter5/",
            "relUrl": "/chapter5/",
            "date": " • Mar 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "4장 누락된 데이터",
            "content": "&#54596;&#50836;&#54620; &#54056;&#53412;&#51648; . &#45936;&#51060;&#53552;&#51032; &#49688;&#51665; . url = &quot;https://biostat.app.vumc.org/wiki/pub/Main/DataSets/titanic3.xls&quot; df = pd.read_excel(url) orig_df = df . 4.1 &#45572;&#46973;&#46108; &#45936;&#51060;&#53552;&#51032; &#48516;&#49437; . df.isnull().mean() * 100 . pclass 0.000000 survived 0.000000 name 0.000000 sex 0.000000 age 20.091673 sibsp 0.000000 parch 0.000000 ticket 0.000000 fare 0.076394 cabin 77.463713 embarked 0.152788 boat 62.872422 body 90.756303 home.dest 43.086325 dtype: float64 . import missingno as msno ax = msno.matrix(orig_df.sample(500)) plt.show() . fig, ax = plt.subplots(figsize=(6, 4)) (1 - df.isnull().mean()).abs().plot.bar(ax=ax) plt.show() . ax = msno.bar(orig_df.sample(500)) plt.show() . ax = msno.heatmap(df, figsize=(6, 6)) plt.show() . ax = msno.dendrogram(df) plt.show() . 4.2 &#45572;&#46973;&#46108; &#45936;&#51060;&#53552;&#51032; &#49325;&#51228; . df1 = df.dropna() . df1 = df.drop(columns=&quot;cabin&quot;) . df1 = df.dropna(axis=1) . 4.3 &#45936;&#51060;&#53552;&#51032; &#45824;&#52824; . from sklearn.impute import SimpleImputer num_cols = df.select_dtypes( include=&quot;number&quot; ).columns im = SimpleImputer() # 평균 imputed = im.fit_transform(df[num_cols]) . 4.4 &#51648;&#49884;&#51088; &#50676;&#51032; &#52628;&#44032; . def add_indicator(col): def wrapper(df): return df[col].isna().astype(int) return wrapper df1 = df.assign(cabin_missing=add_indicator(&quot;cabin&quot;)) . df1.head(10) . pclass survived name sex age sibsp parch ticket fare cabin embarked boat body home.dest cabin_missing . 0 1 | 1 | Allen, Miss. Elisabeth Walton | female | 29.0000 | 0 | 0 | 24160 | 211.3375 | B5 | S | 2 | NaN | St Louis, MO | 0 | . 1 1 | 1 | Allison, Master. Hudson Trevor | male | 0.9167 | 1 | 2 | 113781 | 151.5500 | C22 C26 | S | 11 | NaN | Montreal, PQ / Chesterville, ON | 0 | . 2 1 | 0 | Allison, Miss. Helen Loraine | female | 2.0000 | 1 | 2 | 113781 | 151.5500 | C22 C26 | S | NaN | NaN | Montreal, PQ / Chesterville, ON | 0 | . 3 1 | 0 | Allison, Mr. Hudson Joshua Creighton | male | 30.0000 | 1 | 2 | 113781 | 151.5500 | C22 C26 | S | NaN | 135.0 | Montreal, PQ / Chesterville, ON | 0 | . 4 1 | 0 | Allison, Mrs. Hudson J C (Bessie Waldo Daniels) | female | 25.0000 | 1 | 2 | 113781 | 151.5500 | C22 C26 | S | NaN | NaN | Montreal, PQ / Chesterville, ON | 0 | . 5 1 | 1 | Anderson, Mr. Harry | male | 48.0000 | 0 | 0 | 19952 | 26.5500 | E12 | S | 3 | NaN | New York, NY | 0 | . 6 1 | 1 | Andrews, Miss. Kornelia Theodosia | female | 63.0000 | 1 | 0 | 13502 | 77.9583 | D7 | S | 10 | NaN | Hudson, NY | 0 | . 7 1 | 0 | Andrews, Mr. Thomas Jr | male | 39.0000 | 0 | 0 | 112050 | 0.0000 | A36 | S | NaN | NaN | Belfast, NI | 0 | . 8 1 | 1 | Appleton, Mrs. Edward Dale (Charlotte Lamson) | female | 53.0000 | 2 | 0 | 11769 | 51.4792 | C101 | S | D | NaN | Bayside, Queens, NY | 0 | . 9 1 | 0 | Artagaveytia, Mr. Ramon | male | 71.0000 | 0 | 0 | PC 17609 | 49.5042 | NaN | C | NaN | 22.0 | Montevideo, Uruguay | 1 | .",
            "url": "https://deep-diver.github.io/pocket-ml-reference-korean/chapter4/",
            "relUrl": "/chapter4/",
            "date": " • Mar 7, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "3장 분류 문제 둘러보기(타이타닉 데이터셋)",
            "content": "3.2 &#54596;&#50836;&#54620; &#54056;&#53412;&#51648; . 3.5 &#45936;&#51060;&#53552;&#51032; &#49688;&#51665; . url = &quot;https://biostat.app.vumc.org/wiki/pub/Main/DataSets/titanic3.xls&quot; df = pd.read_excel(url) orig_df = df . df.columns . Index([&#39;pclass&#39;, &#39;survived&#39;, &#39;name&#39;, &#39;sex&#39;, &#39;age&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;ticket&#39;, &#39;fare&#39;, &#39;cabin&#39;, &#39;embarked&#39;, &#39;boat&#39;, &#39;body&#39;, &#39;home.dest&#39;], dtype=&#39;object&#39;) . 3.6 &#45936;&#51060;&#53552;&#51032; &#51221;&#47532; . df.dtypes . pclass int64 survived int64 name object sex object age float64 sibsp int64 parch int64 ticket object fare float64 cabin object embarked object boat object body float64 home.dest object dtype: object . df.shape . (1309, 14) . df.describe().iloc[:, :2] . pclass survived . count 1309.000000 | 1309.000000 | . mean 2.294882 | 0.381971 | . std 0.837836 | 0.486055 | . min 1.000000 | 0.000000 | . 25% 2.000000 | 0.000000 | . 50% 3.000000 | 0.000000 | . 75% 3.000000 | 1.000000 | . max 3.000000 | 1.000000 | . df.isnull().sum() . pclass 0 survived 0 name 0 sex 0 age 263 sibsp 0 parch 0 ticket 0 fare 1 cabin 1014 embarked 2 boat 823 body 1188 home.dest 564 dtype: int64 . mask = df.isnull().any(axis=1) . mask.head() . 0 True 1 True 2 True 3 True 4 True dtype: bool . df[mask].body.head() . 0 NaN 1 NaN 2 NaN 3 135.0 4 NaN Name: body, dtype: float64 . df.sex.value_counts(dropna=False) . male 843 female 466 Name: sex, dtype: int64 . df.embarked.value_counts(dropna=False) . S 914 C 270 Q 123 NaN 2 Name: embarked, dtype: int64 . 3.7 &#53945;&#51669;&#51032; &#49373;&#49457; . name = df.name name.head(3) . 0 Allen, Miss. Elisabeth Walton 1 Allison, Master. Hudson Trevor 2 Allison, Miss. Helen Loraine Name: name, dtype: object . df = df.drop( columns=[&quot;name&quot;, &quot;ticket&quot;, &quot;home.dest&quot;, &quot;boat&quot;, &quot;body&quot;, &quot;cabin&quot;] ) . df = pd.get_dummies(df) . df.columns . Index([&#39;pclass&#39;, &#39;survived&#39;, &#39;age&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;fare&#39;, &#39;sex_female&#39;, &#39;sex_male&#39;, &#39;embarked_C&#39;, &#39;embarked_Q&#39;, &#39;embarked_S&#39;], dtype=&#39;object&#39;) . df = df.drop(columns=&quot;sex_male&quot;) . df = pd.get_dummies(df, drop_first=True) . df.columns . Index([&#39;pclass&#39;, &#39;survived&#39;, &#39;age&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;fare&#39;, &#39;sex_female&#39;, &#39;embarked_C&#39;, &#39;embarked_Q&#39;, &#39;embarked_S&#39;], dtype=&#39;object&#39;) . y = df.survived X = df.drop(columns=&quot;survived&quot;) . 3.8 &#49368;&#54540; &#45936;&#51060;&#53552; . X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42) . 3.9 &#45936;&#51060;&#53552;&#51032; &#45824;&#52824; . from sklearn.experimental import ( enable_iterative_imputer, ) from sklearn import impute . num_cols = [ &quot;pclass&quot;, &quot;age&quot;, &quot;sibsp&quot;, &quot;parch&quot;, &quot;fare&quot;, &quot;sex_female&quot;, ] . imputer = impute.IterativeImputer() imputed = imputer.fit_transform( X_train[num_cols] ) X_train.loc[:, num_cols] = imputed imputed = imputer.transform(X_test[num_cols]) X_test.loc[:, num_cols] = imputed . meds = X_train.median() X_train = X_train.fillna(meds) X_test = X_test.fillna(meds) . X_train.head() . pclass age sibsp parch fare sex_female embarked_C embarked_Q embarked_S . 1214 3.0 | 26.984481 | 0.0 | 0.0 | 8.6625 | 0.0 | 0 | 0 | 1 | . 677 3.0 | 26.000000 | 0.0 | 0.0 | 7.8958 | 0.0 | 0 | 0 | 1 | . 534 2.0 | 19.000000 | 0.0 | 0.0 | 26.0000 | 1.0 | 0 | 0 | 1 | . 1174 3.0 | 0.437798 | 8.0 | 2.0 | 69.5500 | 1.0 | 0 | 0 | 1 | . 864 3.0 | 28.000000 | 0.0 | 0.0 | 7.7750 | 1.0 | 0 | 0 | 1 | . 3.10 &#45936;&#51060;&#53552;&#51032; &#54364;&#51456;&#54868; . cols = &quot;pclass,age,sibsp,fare&quot;.split(&quot;,&quot;) sca = preprocessing.StandardScaler() . X_train = sca.fit_transform(X_train) X_train = pd.DataFrame(X_train[:, :4], columns=cols) X_test = sca.transform(X_test) X_test = pd.DataFrame(X_test[:, :4], columns=cols) . 3.11 &#47532;&#54057;&#53552;&#47553; . def tweak_titanic(df): df = df.drop( columns=[ &quot;name&quot;, &quot;ticket&quot;, &quot;home.dest&quot;, &quot;boat&quot;, &quot;body&quot;, &quot;cabin&quot;, ] ).pipe(pd.get_dummies, drop_first=True) return df def get_train_test_X_y(df, y_col, size=0.3, std_cols=None): y = df[y_col] X = df.drop(columns=y_col) X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=size, random_state=42 ) cols = X.columns num_cols = [ &quot;pclass&quot;, &quot;age&quot;, &quot;sibsp&quot;, &quot;parch&quot;, &quot;fare&quot;, ] fi = impute.IterativeImputer() X_train.loc[:, num_cols] = fi.fit_transform(X_train[num_cols]) X_test.loc[:, num_cols] = fi.transform(X_test[num_cols]) if std_cols: std = preprocessing.StandardScaler() X_train.loc[:, std_cols] = std.fit_transform(X_train[std_cols]) X_test.loc[:, std_cols] = std.transform(X_test[std_cols]) return X_train, X_test, y_train, y_test . ti_df = tweak_titanic(orig_df) std_cols = &quot;pclass,age,sibsp,fare&quot;.split(&quot;,&quot;) X_train, X_test, y_train, y_test = get_train_test_X_y(ti_df, &quot;survived&quot;, std_cols=std_cols) . 3.12 &#48288;&#51060;&#49828;&#46972;&#51064; &#47784;&#45944; . from sklearn.dummy import DummyClassifier bm = DummyClassifier() bm.fit(X_train, y_train) bm.score(X_test, y_test) # 정확도 . 0.5623409669211196 . from sklearn import metrics metrics.precision_score(y_test, bm.predict(X_test)) . 0.44 . 3.13 &#45796;&#50577;&#54620; &#50508;&#44256;&#47532;&#51608; . X = pd.concat([X_train, X_test]) y = pd.concat([y_train, y_test]) . from sklearn import model_selection from sklearn.dummy import DummyClassifier from sklearn.linear_model import ( LogisticRegression, ) from sklearn.tree import DecisionTreeClassifier from sklearn.neighbors import ( KNeighborsClassifier, ) from sklearn.naive_bayes import GaussianNB from sklearn.svm import SVC from sklearn.ensemble import ( RandomForestClassifier, ) import xgboost . for model in [ DummyClassifier, LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, RandomForestClassifier, xgboost.XGBClassifier, ]: cls = model() kfold = model_selection.KFold(n_splits=10, random_state=42) s = model_selection.cross_val_score(cls, X, y, scoring=&quot;roc_auc&quot;, cv=kfold) print(f&quot;{model.__name__:22} AUC: {s.mean():.3f} STD: {s.std():.2f}&quot;) . DummyClassifier AUC: 0.523 STD: 0.03 LogisticRegression AUC: 0.843 STD: 0.03 DecisionTreeClassifier AUC: 0.762 STD: 0.03 KNeighborsClassifier AUC: 0.830 STD: 0.05 GaussianNB AUC: 0.817 STD: 0.04 SVC AUC: 0.837 STD: 0.05 RandomForestClassifier AUC: 0.845 STD: 0.03 XGBClassifier AUC: 0.863 STD: 0.04 . 3.14 &#49828;&#53468;&#53433; . from mlxtend.classifier import ( StackingClassifier, ) clfs = [ x() for x in [ LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier, GaussianNB, SVC, RandomForestClassifier, ] ] stack = StackingClassifier( classifiers=clfs, meta_classifier=LogisticRegression(), ) kfold = model_selection.KFold(n_splits=10, random_state=42) s = model_selection.cross_val_score(stack, X, y, scoring=&quot;roc_auc&quot;, cv=kfold) print(f&quot;{stack.__class__.__name__} AUC: {s.mean():.3f} STD: {s.std():.2f}&quot;) . StackingClassifier AUC: 0.785 STD: 0.04 . 3.15 &#47784;&#45944; &#47564;&#46308;&#44592; . rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=42) rf.fit(X_train, y_train) . RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None, oob_score=False, random_state=42, verbose=0, warm_start=False) . 3.16 &#47784;&#45944;&#51032; &#54217;&#44032; . rf.score(X_test, y_test) . 0.7837150127226463 . metrics.precision_score(y_test, rf.predict(X_test)) . 0.7916666666666666 . for col, val in sorted(zip(X_train.columns, rf.feature_importances_), key=lambda x: x[1], reverse=True)[:5]: print(f&quot;{col:10}{val:10.3f}&quot;) . age 0.285 fare 0.262 sex_male 0.241 pclass 0.089 sibsp 0.050 . 3.17 &#47784;&#45944;&#51032; &#52572;&#51201;&#54868; . rf4 = ensemble.RandomForestClassifier() params = { &quot;max_features&quot;: [0.4, &quot;auto&quot;], &quot;n_estimators&quot;: [15, 200], &quot;min_samples_leaf&quot;: [1, 0.1], &quot;random_state&quot;: [42], } cv = model_selection.GridSearchCV(rf4, params, n_jobs=-1).fit(X_train, y_train) print(cv.best_params_) . {&#39;max_features&#39;: 0.4, &#39;min_samples_leaf&#39;: 1, &#39;n_estimators&#39;: 200, &#39;random_state&#39;: 42} . rf5 = ensemble.RandomForestClassifier( **{ &quot;max_features&quot;: &quot;auto&quot;, &quot;min_samples_leaf&quot;: 0.1, &quot;n_estimators&quot;: 200, &quot;random_state&quot;: 42, } ) rf5.fit(X_train, y_train) rf5.score(X_test, y_test) . 0.7073791348600509 . 3.18 &#50724;&#52264; &#54665;&#47148; . from sklearn.metrics import confusion_matrix y_pred = rf5.predict(X_test) confusion_matrix(y_test, y_pred) . array([[217, 7], [108, 61]]) . mapping = {0: &quot;died&quot;, 1: &quot;survived&quot;} fig, ax = plt.subplots(figsize=(6, 6)) cm_viz = ConfusionMatrix( rf5, classes=[&quot;died&quot;, &quot;survived&quot;], label_encoder=mapping, ) cm_viz.score(X_test, y_test) cm_viz.poof() plt.show() . 3.19 ROC &#44257;&#49440; . y_pred = rf5.predict(X_test) roc_auc_score(y_test, y_pred) . 0.6648483727810651 . fig, ax = plt.subplots(figsize=(6, 6)) roc_viz = ROCAUC(rf5) roc_viz.score(X_test, y_test) roc_viz.poof() plt.show() . 3.20 &#54617;&#49845; &#44257;&#49440; . import numpy as np fig, ax = plt.subplots(figsize=(6, 4)) cv = StratifiedKFold(12) sizes = np.linspace(0.3, 1.0, 10) lc_viz = LearningCurve( rf5, cv=cv, train_sizes=sizes, scoring=&quot;f1_weighted&quot;, n_jobs=4, ax=ax, ) lc_viz.fit(X, y) lc_viz.poof() plt.show() . 3.21 &#47784;&#45944;&#51032; &#48176;&#54252; . import pickle pic = pickle.dumps(rf5) rf6 = pickle.loads(pic) y_pred = rf6.predict(X_test) roc_auc_score(y_test, y_pred) . 0.6648483727810651 .",
            "url": "https://deep-diver.github.io/pocket-ml-reference-korean/chapter3/",
            "relUrl": "/chapter3/",
            "date": " • Mar 7, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://deep-diver.github.io/pocket-ml-reference-korean/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://deep-diver.github.io/pocket-ml-reference-korean/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}